\documentclass[a4paper, 12pt]{article}

%% end ox-latex features


\input{lab_pre}

\labno{1}
\labtopic{Study and Empirical Analysis of Algorithms for Determining Fibonacci N-th Term}


\begin{document}

\include{lab_titlepage}

\section{Algorithm Analysis}
\label{sec:orgc0ff396}
\subsection{Objective}
\label{sec:orgbd7f39e}
Study and analyze different algorithms for determining Fibonacci n-th term.
\subsection{Tasks}
\label{sec:orgdc320c1}
\begin{enumerate}
\item Implement at least 3 algorithms for determining Fibonacci n-th term;
\item Decide properties of input format that will be used for algorithm analysis;
\item Decide the comparison metric for the algorithms;
\item Analyze empirically the algorithms;
\item Present the results of the obtained data;
\item Deduce conclusions of the laboratory.
\end{enumerate}
\subsection{Theoretical Notes}
\label{sec:org15e013d}
An alternative to mathematical analysis of complexity is empirical analysis.
This may be useful for: obtaining preliminary information on the complexity class of an
algorithm; comparing the efficiency of two (or more) algorithms for solving the same problems;
comparing the efficiency of several implementations of the same algorithm; obtaining information on the
efficiency of implementing an algorithm on a particular computer.
In the empirical analysis of an algorithm, the following steps are usually followed:
\begin{enumerate}
\item The purpose of the analysis is established.
\item Choose the efficiency metric to be used (number of executions of an operation (s) or time
\end{enumerate}
execution of all or part of the algorithm.
\begin{enumerate}
\item The properties of the input data in relation to which the analysis is performed are established
\end{enumerate}
(data size or specific properties).
\begin{enumerate}
\item The algorithm is implemented in a programming language.
\item Generating multiple sets of input data.
\item Run the program for each input data set.
\item The obtained data are analyzed.
\end{enumerate}

The choice of the efficiency measure depends on the purpose of the analysis. If, for example, the
aim is to obtain information on the complexity class or even checking the accuracy of a theoretical
estimate then it is appropriate to use the number of operations performed. But if the goal is to assess the
behavior of the implementation of an algorithm then execution time is appropriate.

After the execution of the program with the test data, the results are recorded and, for the purpose
of the analysis, either synthetic quantities (mean, standard deviation, etc.) are calculated or a graph with
appropriate pairs of points (i.e. problem size, efficiency measure) is plotted.
\subsection{Introduction}
\label{sec:orgdaa0968}
The Fibonacci sequence is the series of numbers where each number is the sum of the two
preceding numbers. For example: 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, …
Mathematically we can describe this as: xn= xn-1 + xn-2.

Many sources claim this sequence was first discovered or "invented" by Leonardo Fibonacci. The
Italian mathematician, who was born around A.D. 1170, was initially known as Leonardo of Pisa. In the
19th century, historians came up with the nickname Fibonacci (roughly meaning "son of the Bonacci
clan") to distinguish the mathematician from another famous Leonardo of Pisa.
There are others who say he did not. Keith Devlin, the author of Finding Fibonacci: The Quest to
Rediscover the Forgotten Mathematical Genius Who Changed the World, says there are ancient Sanskrit
texts that use the Hindu-Arabic numeral system - predating Leonardo of Pisa by centuries.
But, in 1202 Leonardo of Pisa published a mathematical text, Liber Abaci. It was a “cookbook” written
for tradespeople on how to do calculations. The text laid out the Hindu-Arabic arithmetic useful for
tracking profits, losses, remaining loan balances, etc, introducing the Fibonacci sequence to the Western
world.

Traditionally, the sequence was determined just by adding two predecessors to obtain a new
number, however, with the evolution of computer science and algorithmics, several distinct methods for
determination have been uncovered. The methods can be grouped in 4 categories, Recursive Methods,
Dynamic Programming Methods, Matrix Power Methods, and Benet Formula Methods. All those can be
implemented naively or with a certain degree of optimization, that boosts their performance during
analysis.

As mentioned previously, the performance of an algorithm can be analyzed mathematically
(derived through mathematical reasoning) or empirically (based on experimental observations).
Within this laboratory, we will be analyzing the 6 algorithms empirically.
\subsection{Comparison Metric}
\label{sec:orgfae4a6a}
The comparison metric for this laboratory work will be considered the time of execution of each algorithm (T(n)).
\subsection{Input Format}
\label{sec:org913c5ec}
As input, each algorithm will receive two series of numbers that will contain the order of the
Fibonacci terms being looked up. The first series will have a more limited scope, (5, 7, 10, 12, 15, 17, 20,
22, 25, 27, 30, 32, 35, 37, 40, 42, 45), to accommodate the recursive method, while the second series will
have a bigger scope to be able to compare the other algorithms between themselves (501, 631, 794, 1000,
1259, 1585, 1995, 2512, 3162, 3981, 5012, 6310, 7943, 10000, 12589, 15849).
\section{Implementation}
\label{sec:org178d09a}
All six algorithms will be implemented in their naïve form in python an analyzed empirically.
based on the time required for their completion. While the general trend of the results may be similar to
other experimental observations, the particular efficiency in rapport with input will vary depending on memory of the device used.
\subsection{Helper Code}
\label{sec:orgf0edea2}
We will be plotting the performance of algorithms using \texttt{matplotlib}, by taking the time taken to compute numbers at even inrervals. For that we define a helper function:
\begin{verbatim}
import time
import matplotlib.pyplot as plt

def plotFibPerformance(fibFunc, numList):
    times = []
    for n in numList:
        start = time.perf_counter()
        fibFunc(n)
        times.append(time.perf_counter() - start)

    plt.figure(figsize=(10, 6))
    plt.plot(numList, times, 'bo-')
    plt.xlabel('n-th Fibonacci Number')
    plt.ylabel('Time (seconds)')
    plt.title(f'Performance of {fibFunc.__name__}')
    plt.grid(True)

    #return times
    return plt.gcf()
\end{verbatim}

And we define our input lists:
\begin{verbatim}
input1 = [5, 7, 10, 12, 15, 17, 20, 22, 25, 27, 30, 32, 35,]
input2 = [501, 631, 794, 1000, 1259, 1585, 1995, 2512, 3162, 3981, 5012, 6310, 7943,]
\end{verbatim}
\subsection{Recursive Method}
\label{sec:orgdd16fab}
The recursive Fibonacci implementation directly mirrors the mathematical recurrence relation Fn = Fn-1 + Fn-2. For each n, it recursively calculates F(n-1) and F(n-2) until reaching base cases of n=0 or n=1. While elegant, this creates an exponential time complexity of O(2\textsuperscript{n}) as it recomputes the same Fibonacci numbers many times. For example, computing F(4) requires computing F(3) and F(2), but F(3) also requires computing F(2) again.
\subsubsection{Implementation}
\label{sec:org88fddfb}
\begin{verbatim}
def recursiveFib(n):
    if n <= 1:  # Base cases
        return n
    return recursiveFib(n-1) + recursiveFib(n-2)
\end{verbatim}
\subsubsection{Results}
\label{sec:orgd1d0c06}
Here we are running the function for every number in the list:
\begin{verbatim}
plotFibPerformance(recursiveFib, input1)
\end{verbatim}
\begin{figure}[htbp]  % 'htbp' controls the placement (here, top, bottom, or page)
  \centering  % Centers the figure
  \includegraphics[width=\textwidth]{./recursiveFib.png}  % Include the image
  \caption{Recursive Method}  % Caption for the figure
  \label{fig:yourlabel}  % Label for referencing the figure
\end{figure}
\subsection{Memoized Recursive}
\label{sec:org1ca3c80}
Memoization caches previously computed values to avoid redundant calculations.
\subsubsection{Implementation}
\label{sec:org9603c17}
\begin{verbatim}
def memoFib(n, memo=None):
    if memo is None: memo = {}
    if n <= 1: return n
    if n not in memo:
        memo[n] = memoFib(n-1, memo) + memoFib(n-2, memo)
    return memo[n]
\end{verbatim}
\subsubsection{Results}
\label{sec:org3b0e4df}
As expected, we achieve T(n) time complexity:
\begin{verbatim}
plotFibPerformance(memoFib, input1)
\end{verbatim}
\begin{figure}[htbp]  % 'htbp' controls the placement (here, top, bottom, or page)
  \centering  % Centers the figure
  \includegraphics[width=\textwidth]{./memoFib.png}  % Include the image
  \caption{Memoized Recursive}  % Caption for the figure
\end{figure}
\subsection{Matrix Exponentiation}
\label{sec:org3016d6d}
The matrix exponentiation method computes Fibonacci numbers in T(log n) time by exploiting the relationship between consecutive Fibonacci numbers and matrix multiplication. The key insight is that:

\[ \begin{bmatrix} F_{n+1} & F_n \\ F_n & F_{n-1} \end{bmatrix} = \begin{bmatrix} 1 & 1 \\ 1 & 0 \end{bmatrix}^n \]

Therefore, \(F_n\) can be computed by raising the base matrix to the nth power using fast exponentiation.
\subsubsection{Implementation}
\label{sec:org518793c}
This will allow us to deal with overflows
\begin{verbatim}
MOD = 10**9 + 7
\end{verbatim}

Function to multiply two 2x2 Matrices:
\begin{verbatim}
def multiply(A, B):
    # Matrix to store the result
    C = [[0, 0], [0, 0]]

    # Matrix Multiply
    C[0][0] = (A[0][0] * B[0][0] + A[0][1] * B[1][0]) % MOD
    C[0][1] = (A[0][0] * B[0][1] + A[0][1] * B[1][1]) % MOD
    C[1][0] = (A[1][0] * B[0][0] + A[1][1] * B[1][0]) % MOD
    C[1][1] = (A[1][0] * B[0][1] + A[1][1] * B[1][1]) % MOD

    # Copy the result back to the first matrix
    A[0][0] = C[0][0]
    A[0][1] = C[0][1]
    A[1][0] = C[1][0]
    A[1][1] = C[1][1]
\end{verbatim}

Function to find (Matrix \(M ^{expo}\))
\begin{verbatim}
def power(M, expo):
    # Initialize result with identity matrix
    ans = [[1, 0], [0, 1]]

    # Fast Exponentiation
    while expo:
        if expo & 1:
            multiply(ans, M)
        multiply(M, M)
        expo >>= 1

    return ans
\end{verbatim}

And the fibonacci function per-ce:
\begin{verbatim}
def matrixExpoFib(n):
    # Base case
    if n == 0 or n == 1:
        return 1

    M = [[1, 1], [1, 0]]
    # F(0) = 0, F(1) = 1
    F = [[1, 0], [0, 0]]

    # Multiply matrix M (n - 1) times
    res = power(M, n - 1)

    # Multiply Resultant with Matrix F
    multiply(res, F)

    return res[0][0] % MOD
\end{verbatim}
\subsubsection{Results}
\label{sec:org8ce71eb}
Here we measure the function, Roughly seeing the T(log n) complexity.
\begin{verbatim}
plotFibPerformance(matrixExpoFib, input2)
\end{verbatim}
\begin{figure}[htbp]  % 'htbp' controls the placement (here, top, bottom, or page)
  \centering  % Centers the figure
  \includegraphics[width=\textwidth]{./matrixExpoFib.png}  % Include the image
  \caption{Matrix Exponentiation}  % Caption for the figure
\end{figure}
\subsection{Fast Doubling method}
\label{sec:org7e9f33e}
The Matrix Exponentiation Method is already discussed before. The Doubling Method can be seen as an improvement to the matrix exponentiation method to find the N-th Fibonacci number although it doesn’t use matrix multiplication itself.

The Fibonacci recursive sequence is given by 
\[
F(n+1) = F(n) + F(n-1)
\]

The Matrix Exponentiation method uses the following formula
The fast doubling method leverages the relationships between consecutive Fibonacci numbers using these identities:
\begin{align}
\label{eq:4}
F_{2n} = F_n(2F_{n+1} - F_n) \\
F_{2n+1} = F_{n+1}^2 + F_n^2
\end{align}
Like matrix exponentiation, this achieves T(log n) time complexity through recursive doubling.
\subsubsection{Implementation}
\label{sec:org34c3070}
\begin{verbatim}
MOD = 1000000007

def fastDoublingRec(n, res): 

    # Base Condition 
    if (n == 0): 
        res[0] = 0
        res[1] = 1
        return

    fastDoublingRec((n // 2), res) 

    # Here a = F(n) 
    a = res[0] 

    # Here b = F(n+1) 
    b = res[1] 

    c = 2 * b - a 

    if (c < 0): 
        c += MOD 

    # As F(2n) = F(n)[2F(n+1) – F(n)] 
    # Here c = F(2n) 
    c = (a * c) % MOD 

    # As F(2n + 1) = F(n)^2 + F(n+1)^2 
    # Here d = F(2n + 1) 
    d = (a * a + b * b) % MOD 

    # Check if N is odd 
    # or even 
    if (n % 2 == 0): 
        res[0] = c 
        res[1] = d 
    else : 
        res[0] = d 
        res[1] = c + d 

def fastDoublingFib(n):
    res = [0] * 2
    fastDoublingRec(n, res)
    return res[0]
\end{verbatim}
\subsubsection{Results}
\label{sec:org61d5a55}
Here we measure the function. As expected, it is much faster than the matrix exponentiation method, whilst still having resemblence of the \(log(n)\) graph.
\begin{verbatim}
plotFibPerformance(fastDoublingFib, input2)
\end{verbatim}
\begin{figure}[htbp]  % 'htbp' controls the placement (here, top, bottom, or page)
  \centering  % Centers the figure
  \includegraphics[width=\textwidth]{./fastDoublingFib.png}  % Include the image
  \caption{Fast Doubling}  % Caption for the figure
\end{figure}
\subsection{Dinamic Programming}
\label{sec:orgcc4a8d9}
The Dynamic Programming method, similar to the recursive method, takes the straightforward approach of calculating the n-th term. However, instead of calling the function upon itself, it stores just the previous two values. The recurrence relation is:
\[F_n = F_{n-1} + F_{n-2}\]
\subsubsection{Implementation}
\label{sec:org27d0eab}
\begin{verbatim}
def dpFib(n):
    if n <= 1: return n
    a, b = 0, 1
    for _ in range(2, n + 1):
        a, b = b, a + b  # Store only previous two values
    return b
\end{verbatim}

This is optimal for computing a single Fibonacci number with respect to time complexity.
\subsubsection{Results}
\label{sec:orgedda308}
Showing excellent results with a time
complexity denoted in a corresponding graph of T(n):
\begin{verbatim}
plotFibPerformance(dpFib, input2)
\end{verbatim}
\begin{figure}[htbp]  % 'htbp' controls the placement (here, top, bottom, or page)
  \centering  % Centers the figure
  \includegraphics[width=\textwidth]{./dinamicFib.png}  % Include the image
  \caption{Dinamic Programming}  % Caption for the figure
\end{figure}
\subsection{Binet Formula Method}
\label{sec:orga791916}
The Binet Formula Method is another unconventional way of calculating the n-th term of the
Fibonacci series, as it operates using the Golden Ratio formula, or phi. However, due to its nature of
requiring the usage of decimal numbers, at some point, the rounding error of python that accumulates,
begins affecting the results significantly.
\subsubsection{Implementation}
\label{sec:org99be789}
\begin{verbatim}
import math


input3 = [5, 7, 10, 12, 15, 17, 20, 22, 25, 27, 30, 32, 35, 47, 50, 55, 65, 70, 80, 100, 150, 166, 200]

def binetFib(n):

    # Golden ratio (phi) and its negative counterpart (psi)
    phi = (1 + math.sqrt(5)) / 2
    psi = (1 - math.sqrt(5)) / 2

    # Compute Fibonacci number using full Binet's formula
    return round((math.pow(phi, n) - math.pow(psi, n)) / math.sqrt(5))
\end{verbatim}
\subsubsection{Results}
\label{sec:org9feab26}
The errors starting with around 75-th number make the algorithm unusable in practice, despite its speed.
\begin{verbatim}
plotFibPerformance(binetFib, input3)
\end{verbatim}
\begin{figure}[htbp]  % 'htbp' controls the placement (here, top, bottom, or page)
  \centering  % Centers the figure
  \includegraphics[width=\textwidth]{./binetFormulaFib.png}  % Include the image
  \caption{Binet Formula}  % Caption for the figure
\end{figure}
\section{Conclusion}
\label{sec:orgedc434d}
In this laboratory, we analyzed various algorithms for calculating Fibonacci numbers, focusing on their empirical performance. Six distinct methods were implemented and tested: the Recursive Method, Memoized Recursive Method, Matrix Exponentiation, Fast Doubling Method, Dynamic Programming, and the Binet Formula. The main comparison metric was the execution time of each algorithm, measured across different input sizes.

The basic \textbf{\textbf{Recursive Method}} demonstrated poor performance as the input size increased due to its exponential time complexity of \(O(2^n)\). This inefficiency was evident in the execution times, particularly for larger values of n, where the algorithm required excessive computation due to recalculating the same Fibonacci numbers multiple times.

The \textbf{\textbf{Memoized Recursive Method}} showed significant improvement by storing previously computed values, which reduced the time complexity from \(O(2^n)\) to \(O(n)\). This method proved to be much faster and more efficient than the plain recursive approach, particularly when dealing with larger values of n.

The \textbf{\textbf{Matrix Exponentiation Method}} used matrix multiplication to calculate Fibonacci numbers in \(O(\log n)\) time. This logarithmic time complexity resulted in a considerable speedup compared to the recursive methods, and it was much faster for larger input sizes. The graph data confirmed the expected \(O(\log n)\) relationship between input size and execution time, making it a viable option for more extensive computations.

The \textbf{\textbf{Fast Doubling Method}} further optimized the matrix exponentiation approach by leveraging the relationships between consecutive Fibonacci numbers. Like matrix exponentiation, it achieved \(O(\log n)\) time complexity but outperformed it in terms of execution speed. This method was the most efficient for large input sizes, providing both faster execution and maintaining accuracy in the results.

The \textbf{\textbf{Dynamic Programming Method}} stored only the last two Fibonacci numbers at each step, which made it highly efficient. With \(O(n)\) time complexity and minimal space usage, this method performed excellently across all input sizes, being both fast and memory-efficient. It stands out as a reliable and optimal choice for computing Fibonacci numbers in practice.

Lastly, the \textbf{\textbf{Binet Formula}} provided a fast way to calculate Fibonacci numbers using the Golden Ratio. However, this method became unreliable for large input sizes due to rounding errors that accumulated as the Fibonacci numbers grew. While it demonstrated fast execution for smaller numbers, the lack of accuracy with larger n makes it unsuitable for practical applications at scale.

In conclusion, the \textbf{\textbf{Dynamic Programming}} and \textbf{\textbf{Fast Doubling}} methods emerged as the most efficient algorithms for calculating Fibonacci numbers, especially for large input sizes. The Memoized Recursive Method also offered a substantial improvement over the plain recursive method. Although the \textbf{\textbf{Matrix Exponentiation}} method is a strong candidate for moderately large Fibonacci numbers, \textbf{\textbf{Fast Doubling}} proved to be the best option overall in terms of both speed and accuracy. The \textbf{\textbf{Binet Formula}}, while fast, is not recommended for larger Fibonacci numbers due to its accuracy limitations.
\end{document}
